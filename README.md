# llm_load_test

Usage:

Start an OpenAI-compatible server:
  
```bash
vllm serve Qwen/Qwen2.5-1.5B-Instruct
```

Run the load test:

```bash
python test_oai.py
```